## Kafka Set Up
- Make sure you have installed kakfa and zookeeper, if not refer below
- Install Kafka (windows: https://www.youtube.com/watch?v=BwYFuhVhshI , linux: https://www.youtube.com/watch?v=BPi2-xM-Ydc)
- make sure you are in main project directory which is "consumer"

## Run Kafka Consumer
- Create new notebook name "consumer.ipynb" under directroy "consumer/check_setup/kafka/"
- Make sure you are using your environment in jupyter notebook by clicking => Kernel => Change Kernel => myconsumerenv 
- Run below code in consumer.ipynb and keep it running
```ruby
# Install kafka-python
!pip install kafka-python

from kafka import KafkaConsumer
import json
consumer = KafkaConsumer('csv-to-json', bootstrap_servers='localhost:9092', value_deserializer=lambda x: json.loads(x.decode('utf-8')))
for msg in consumer:
    print(msg.value)
```

## Run Kafka Producer
- Create new notebook name "producer.ipynb" under directroy "consumer/check_setup/kafka/"
- Make sure you are using your environment in jupyter notebook by clicking => Kernel => Change Kernel => myconsumerenv 
- Also create csv file name "data.csv" under directory "consumer/check_setup/kafka/" with 3 columns as below.
- ![image](https://github.com/ShubhPatil95/demo/assets/74223025/dc74159c-6785-478d-8e0c-91afc7e9289a)
- Now run below code in producer.ipynb.
```ruby
# Install kafka
!pip install kafka-python

from kafka import KafkaProducer
import json
import csv
producer = KafkaProducer(bootstrap_servers='localhost:9092', value_serializer=lambda v: json.dumps(v).encode('utf-8'),)

with open("data.csv", 'r') as file:
        csv_reader = csv.DictReader(file)
        for row in csv_reader:
            print(row)
            producer.send('csv-to-json', value=row)
```

## Validate data
- Now you can go to consumer.py and verify if you have receieved the data from your csv file. If yes then you have successfully set up the kafka producer and consumer.
